{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio, ClassLabel, Features, load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>SessionID</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Language</th>\n",
       "      <th>Survey_Version</th>\n",
       "      <th>...</th>\n",
       "      <th>RA_cp90</th>\n",
       "      <th>RA_cp95</th>\n",
       "      <th>THD_THD</th>\n",
       "      <th>THD_Min</th>\n",
       "      <th>THD_Max</th>\n",
       "      <th>THD_L5</th>\n",
       "      <th>THD_L10</th>\n",
       "      <th>THD_L50</th>\n",
       "      <th>THD_L90</th>\n",
       "      <th>THD_L95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noorderplantsoen</td>\n",
       "      <td>Noorderplantsoen1</td>\n",
       "      <td>NP101</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-11 08:54:00</td>\n",
       "      <td>2020-03-11 09:04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nld</td>\n",
       "      <td>nldSSIDv1</td>\n",
       "      <td>...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-1312.0</td>\n",
       "      <td>5543.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>-993.0</td>\n",
       "      <td>-1104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noorderplantsoen</td>\n",
       "      <td>Noorderplantsoen1</td>\n",
       "      <td>NP101</td>\n",
       "      <td>73</td>\n",
       "      <td>2020-03-13 00:49:00</td>\n",
       "      <td>2020-03-13 00:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nld</td>\n",
       "      <td>nldSSIDv1</td>\n",
       "      <td>...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-1312.0</td>\n",
       "      <td>5543.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>-993.0</td>\n",
       "      <td>-1104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noorderplantsoen</td>\n",
       "      <td>Noorderplantsoen1</td>\n",
       "      <td>NP102</td>\n",
       "      <td>88</td>\n",
       "      <td>2020-03-13 12:04:00</td>\n",
       "      <td>2020-03-13 12:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nld</td>\n",
       "      <td>nldSSIDv1</td>\n",
       "      <td>...</td>\n",
       "      <td>295.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-275.0</td>\n",
       "      <td>-1402.0</td>\n",
       "      <td>6462.0</td>\n",
       "      <td>3921.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>-1188.0</td>\n",
       "      <td>-126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noorderplantsoen</td>\n",
       "      <td>Noorderplantsoen1</td>\n",
       "      <td>NP103</td>\n",
       "      <td>89</td>\n",
       "      <td>2020-03-13 12:12:00</td>\n",
       "      <td>2020-03-13 12:14:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nld</td>\n",
       "      <td>nldSSIDv1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noorderplantsoen</td>\n",
       "      <td>Noorderplantsoen1</td>\n",
       "      <td>NP106</td>\n",
       "      <td>98</td>\n",
       "      <td>2020-03-13 13:25:00</td>\n",
       "      <td>2020-03-13 13:32:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nld</td>\n",
       "      <td>nldSSIDv1</td>\n",
       "      <td>...</td>\n",
       "      <td>257.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-624.0</td>\n",
       "      <td>-737.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>2914.0</td>\n",
       "      <td>2397.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>-352.0</td>\n",
       "      <td>-447.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LocationID          SessionID GroupID  RecordID          start_time  \\\n",
       "0  Noorderplantsoen  Noorderplantsoen1   NP101         2 2020-03-11 08:54:00   \n",
       "1  Noorderplantsoen  Noorderplantsoen1   NP101        73 2020-03-13 00:49:00   \n",
       "2  Noorderplantsoen  Noorderplantsoen1   NP102        88 2020-03-13 12:04:00   \n",
       "3  Noorderplantsoen  Noorderplantsoen1   NP103        89 2020-03-13 12:12:00   \n",
       "4  Noorderplantsoen  Noorderplantsoen1   NP106        98 2020-03-13 13:25:00   \n",
       "\n",
       "             end_time  latitude  longitude Language Survey_Version  ...  \\\n",
       "0 2020-03-11 09:04:00       NaN        NaN      nld      nldSSIDv1  ...   \n",
       "1 2020-03-13 00:51:00       NaN        NaN      nld      nldSSIDv1  ...   \n",
       "2 2020-03-13 12:08:00       NaN        NaN      nld      nldSSIDv1  ...   \n",
       "3 2020-03-13 12:14:00       NaN        NaN      nld      nldSSIDv1  ...   \n",
       "4 2020-03-13 13:32:00       NaN        NaN      nld      nldSSIDv1  ...   \n",
       "\n",
       "   RA_cp90  RA_cp95  THD_THD  THD_Min  THD_Max  THD_L5  THD_L10  THD_L50  \\\n",
       "0    198.0    152.0     -6.0  -1312.0   5543.0  2294.0   1909.0    533.0   \n",
       "1    198.0    152.0     -6.0  -1312.0   5543.0  2294.0   1909.0    533.0   \n",
       "2    295.0     23.0   -275.0  -1402.0   6462.0  3921.0    323.0   1115.0   \n",
       "3      NaN      NaN      NaN      NaN      NaN     NaN      NaN      NaN   \n",
       "4    257.0    203.0   -624.0   -737.0   6889.0  2914.0   2397.0    969.0   \n",
       "\n",
       "   THD_L90  THD_L95  \n",
       "0   -993.0  -1104.0  \n",
       "1   -993.0  -1104.0  \n",
       "2  -1188.0   -126.0  \n",
       "3      NaN      NaN  \n",
       "4   -352.0   -447.0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load metadata CSV (assuming dataset includes a CSV file linking audio to perceptual attributes)\n",
    "metadata = pd.read_excel(r\"C:\\Users\\pepij\\Downloads\\noorderplantsoen.xlsx\")\n",
    "\n",
    "metadata[\"audio_path\"] = metadata[\"GroupID\"].apply(lambda x: r\"C:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\data\\WAV_Groningen_1\\WAV_Groningen_1\\Noorderplantsoen\\NP\" + x[2:] + \".wav\")\n",
    "\n",
    "# Keep only rows where the file exists\n",
    "metadata = metadata[metadata[\"audio_path\"].apply(os.path.exists)]\n",
    "\n",
    "# Reset index after filtering\n",
    "metadata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "metadata = metadata[['GroupID', 'pleasant', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'eventful', 'monotonous', 'audio_path']]\n",
    "\n",
    "columns_to_convert = [\n",
    "    \"pleasant\", \"chaotic\", \"vibrant\", \"uneventful\", \n",
    "    \"calm\", \"annoying\", \"eventful\", \"monotonous\"\n",
    "]\n",
    "\n",
    "metadata[columns_to_convert] = metadata[columns_to_convert].astype(float).values\n",
    "\n",
    "# Before training — scale your labels\n",
    "means = metadata[columns_to_convert].mean()\n",
    "stds = metadata[columns_to_convert].std()\n",
    "\n",
    "metadata[columns_to_convert] = (metadata[columns_to_convert] - means) / stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroupID</th>\n",
       "      <th>pleasant</th>\n",
       "      <th>chaotic</th>\n",
       "      <th>vibrant</th>\n",
       "      <th>uneventful</th>\n",
       "      <th>calm</th>\n",
       "      <th>annoying</th>\n",
       "      <th>eventful</th>\n",
       "      <th>monotonous</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NP101</td>\n",
       "      <td>1.095060</td>\n",
       "      <td>-0.569061</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>-0.081937</td>\n",
       "      <td>-0.177602</td>\n",
       "      <td>-0.937851</td>\n",
       "      <td>-0.933510</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NP101</td>\n",
       "      <td>1.095060</td>\n",
       "      <td>-0.569061</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>-0.994947</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>-0.937851</td>\n",
       "      <td>0.204205</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NP102</td>\n",
       "      <td>-0.059192</td>\n",
       "      <td>-1.439390</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>0.831073</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>-0.937851</td>\n",
       "      <td>0.204205</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NP106</td>\n",
       "      <td>1.095060</td>\n",
       "      <td>0.301268</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>1.744084</td>\n",
       "      <td>-0.177602</td>\n",
       "      <td>1.066324</td>\n",
       "      <td>0.204205</td>\n",
       "      <td>0.457327</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NP107</td>\n",
       "      <td>1.095060</td>\n",
       "      <td>0.301268</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>0.831073</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>1.066324</td>\n",
       "      <td>-0.933510</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NP158</td>\n",
       "      <td>1.095060</td>\n",
       "      <td>-0.569061</td>\n",
       "      <td>0.812330</td>\n",
       "      <td>-0.081937</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>-0.937851</td>\n",
       "      <td>0.204205</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>NP160</td>\n",
       "      <td>1.095060</td>\n",
       "      <td>-1.439390</td>\n",
       "      <td>-1.722139</td>\n",
       "      <td>0.831073</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>0.064236</td>\n",
       "      <td>-2.071226</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NP160</td>\n",
       "      <td>-0.059192</td>\n",
       "      <td>0.301268</td>\n",
       "      <td>0.812330</td>\n",
       "      <td>-0.994947</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.204205</td>\n",
       "      <td>0.457327</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NP161</td>\n",
       "      <td>-0.059192</td>\n",
       "      <td>0.301268</td>\n",
       "      <td>0.812330</td>\n",
       "      <td>-0.994947</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>1.066324</td>\n",
       "      <td>1.341921</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NP163</td>\n",
       "      <td>-1.213445</td>\n",
       "      <td>-0.569061</td>\n",
       "      <td>0.812330</td>\n",
       "      <td>-0.994947</td>\n",
       "      <td>1.554017</td>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.204205</td>\n",
       "      <td>-0.731724</td>\n",
       "      <td>C:\\Users\\pepij\\OneDrive - Delft University of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GroupID  pleasant   chaotic   vibrant  uneventful      calm  annoying  \\\n",
       "0    NP101  1.095060 -0.569061 -0.454905   -0.081937 -0.177602 -0.937851   \n",
       "1    NP101  1.095060 -0.569061 -0.454905   -0.994947  0.688207 -0.937851   \n",
       "2    NP102 -0.059192 -1.439390 -0.454905    0.831073  0.688207 -0.937851   \n",
       "3    NP106  1.095060  0.301268 -0.454905    1.744084 -0.177602  1.066324   \n",
       "4    NP107  1.095060  0.301268 -0.454905    0.831073  0.688207  1.066324   \n",
       "..     ...       ...       ...       ...         ...       ...       ...   \n",
       "73   NP158  1.095060 -0.569061  0.812330   -0.081937  0.688207 -0.937851   \n",
       "74   NP160  1.095060 -1.439390 -1.722139    0.831073  0.688207  0.064236   \n",
       "75   NP160 -0.059192  0.301268  0.812330   -0.994947  0.688207  0.064236   \n",
       "76   NP161 -0.059192  0.301268  0.812330   -0.994947  0.688207  1.066324   \n",
       "77   NP163 -1.213445 -0.569061  0.812330   -0.994947  1.554017  0.064236   \n",
       "\n",
       "    eventful  monotonous                                         audio_path  \n",
       "0  -0.933510   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "1   0.204205   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "2   0.204205   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "3   0.204205    0.457327  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "4  -0.933510   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "..       ...         ...                                                ...  \n",
       "73  0.204205   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "74 -2.071226   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "75  0.204205    0.457327  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "76  1.341921   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "77  0.204205   -0.731724  C:\\Users\\pepij\\OneDrive - Delft University of ...  \n",
       "\n",
       "[78 rows x 10 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Audio, ClassLabel\n",
    "from transformers import ASTFeatureExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(row):\n",
    "    waveform, sr = torchaudio.load(row['audio_path'])\n",
    "    return {\n",
    "        'filename': f\"{row['GroupID']}.wav\",\n",
    "        'labels': {k: row[k] for k in ['pleasant', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'eventful', 'monotonous']},\n",
    "        # 'labels': [\n",
    "        #     row['pleasant'], row['chaotic'], row['vibrant'], row['uneventful'],\n",
    "        #     row['calm'], row['annoying'], row['eventful'], row['monotonous']\n",
    "        # ],\n",
    "        'audio': {\n",
    "            'path': row['audio_path'],\n",
    "            'array': waveform.squeeze().numpy().reshape(-1),\n",
    "            'sampling_rate': sr\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Step 1: Apply transformation to entire DataFrame\n",
    "records = metadata.apply(load_audio, axis=1)\n",
    "\n",
    "# Step 2: Apply to rows and collect results as list of dicts\n",
    "records = [load_audio(row) for _, row in metadata.iterrows()]\n",
    "\n",
    "# Step 3: Create a new DataFrame directly\n",
    "new_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'NP101.wav',\n",
       " 'labels': {'annoying': 1.0,\n",
       "  'calm': 3.0,\n",
       "  'chaotic': 2.0,\n",
       "  'eventful': 3.0,\n",
       "  'monotonous': 1.0,\n",
       "  'pleasant': 5.0,\n",
       "  'uneventful': 2.0,\n",
       "  'vibrant': 4.0},\n",
       " 'audio': {'path': None,\n",
       "  'array': array([ 9.21832398e-05,  2.42332753e-04,  1.83250348e-04, ...,\n",
       "         -2.55998340e-04, -3.29684844e-04,  0.00000000e+00]),\n",
       "  'sampling_rate': 16000}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(988502,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['audio']['array'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]\n",
    "# De oude format als je eerst numpy array zou maken maar is dus niet nodig zie hierboven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pretrained model and instantiate the feature extractor\n",
    "pretrained_model = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(pretrained_model)\n",
    "model_input_name = feature_extractor.model_input_names[0]\n",
    "SAMPLING_RATE = feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_keys = [\"pleasant\", \"chaotic\", \"vibrant\", \"uneventful\", \"calm\", \"annoying\", \"eventful\", \"monotonous\"]\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_audio(batch):\n",
    "    wavs = [audio[\"array\"] for audio in batch[\"input_values\"]]\n",
    "    inputs = feature_extractor(wavs, sampling_rate=SAMPLING_RATE, return_tensors=\"pt\")\n",
    "    labels = [[row[k] for k in label_keys] for row in batch[\"labels\"]]\n",
    "    return {model_input_name: inputs[model_input_name], \"labels\": torch.tensor(labels, dtype=torch.float32)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data\n",
    "if \"test\" not in dataset:\n",
    "    dataset = dataset.train_test_split(\n",
    "        test_size=0.2, shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=feature_extractor.sampling_rate))\n",
    "dataset = dataset.rename_column(\"audio\", \"input_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transforms\n",
    "dataset[\"train\"].set_transform(preprocess_audio, output_all_columns=False)\n",
    "dataset[\"test\"].set_transform(preprocess_audio, output_all_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[-0.6395, -1.0403, -0.6634,  ..., -0.6391, -0.8450, -1.0111],\n",
       "         [-0.6513, -0.9367, -0.5599,  ..., -0.6642, -0.8131, -0.9661],\n",
       "         [-0.6521, -1.1107, -0.7339,  ..., -0.5819, -0.7898, -1.1639],\n",
       "         ...,\n",
       "         [-0.9587, -1.1572, -0.7804,  ..., -0.9773, -1.0858, -1.2776],\n",
       "         [-0.9500, -1.2287, -0.8519,  ..., -0.9749, -1.1984, -1.2776],\n",
       "         [-0.9315, -1.1641, -0.7873,  ..., -0.9093, -1.0075, -1.2776]]),\n",
       " 'labels': tensor([4., 2., 3., 5., 2., 3., 4., 3.])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers import ASTConfig, ASTForAudioClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from the pretrained model\n",
    "config = ASTConfig.from_pretrained(pretrained_model)\n",
    "\n",
    "# Modify the model's final layer for regression (8 outputs)\n",
    "model = ASTForAudioClassification.from_pretrained(pretrained_model, config=config, ignore_mismatched_sizes=True)\n",
    "model.classifier = nn.Linear(config.hidden_size, 8)\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import torch.nn as nn\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = nn.MSELoss()(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./runs/ast_regressor_test\",\n",
    "    logging_dir=\"./logs/ast_regressor_test\",\n",
    "    report_to=\"none\",\n",
    "    learning_rate=5e-2,  # Learning rate\n",
    "    push_to_hub=False,\n",
    "    num_train_epochs=3,  # Number of epochs\n",
    "    per_device_train_batch_size=8,  # Batch size\n",
    "    eval_strategy=\"epoch\",  # Evaluate after each epoch\n",
    "    save_strategy=\"no\", # Set false to save time\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=False, # Set false to save time\n",
    "    metric_for_best_model=\"rmse\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5, # Decrease to save time\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    mse_value = mean_squared_error(labels, logits)\n",
    "    rmse_value = np.sqrt(mse_value)\n",
    "    mae_value = mean_absolute_error(labels, logits)\n",
    "    r2_value = r2_score(labels, logits)\n",
    "\n",
    "    return {\n",
    "        \"mse\": mse_value,\n",
    "        \"rmse\": rmse_value,\n",
    "        \"mae\": mae_value,\n",
    "        \"r2\": r2_value\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# If you ever want per-attribute RMSE for better model diagnostics:\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits = eval_pred.predictions\n",
    "#     labels = eval_pred.label_ids\n",
    "\n",
    "#     metrics = {}\n",
    "#     for i, name in enumerate([\"pleasant\", \"chaotic\", \"vibrant\", \"uneventful\", \"calm\", \"annoying\", \"eventful\", \"monotonous\"]):\n",
    "#         mse = mean_squared_error(labels[:, i], logits[:, i])\n",
    "#         rmse = np.sqrt(mse)\n",
    "#         metrics[f\"{name}_rmse\"] = rmse\n",
    "\n",
    "#     metrics[\"rmse\"] = np.sqrt(mean_squared_error(labels, logits))\n",
    "#     return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9/24 04:32 < 09:43, 0.03 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1372.202200</td>\n",
       "      <td>104.873871</td>\n",
       "      <td>104.873878</td>\n",
       "      <td>10.240795</td>\n",
       "      <td>9.324855</td>\n",
       "      <td>-109.490479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m trainer = RegressionTrainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\Workspace-Thesis\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\Workspace-Thesis\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2548\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2541\u001b[39m context = (\n\u001b[32m   2542\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2543\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2545\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2546\u001b[39m )\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2548\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\Workspace-Thesis\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3740\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3738\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3740\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3742\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\Workspace-Thesis\\.venv\\Lib\\site-packages\\accelerate\\accelerator.py:2359\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2357\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2358\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2359\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\Workspace-Thesis\\.venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\Workspace-Thesis\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pepij\\OneDrive - Delft University of Technology\\THESIS\\Workspace-Thesis\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 7.0447845, 15.680937 ,  1.3311803, 11.641748 , 13.1720495,\n",
       "        15.890659 , 13.096946 , 14.902811 ],\n",
       "       [ 7.044776 , 15.680927 ,  1.3311661, 11.641735 , 13.172041 ,\n",
       "        15.890648 , 13.096932 , 14.9028015],\n",
       "       [ 7.044776 , 15.680927 ,  1.3311661, 11.641735 , 13.172041 ,\n",
       "        15.890648 , 13.096932 , 14.9028015],\n",
       "       [ 7.0447946, 15.680954 ,  1.3311999, 11.641763 , 13.172063 ,\n",
       "        15.890678 , 13.096966 , 14.902826 ],\n",
       "       [ 7.04479  , 15.680944 ,  1.3311898, 11.641752 , 13.172055 ,\n",
       "        15.890673 , 13.096958 , 14.902819 ],\n",
       "       [ 7.0448003, 15.6809635,  1.3312078, 11.64177  , 13.172068 ,\n",
       "        15.89069  , 13.096977 , 14.902836 ],\n",
       "       [ 7.044779 , 15.680928 ,  1.3311718, 11.641739 , 13.172044 ,\n",
       "        15.890654 , 13.096937 , 14.902804 ],\n",
       "       [ 7.0447917, 15.680948 ,  1.3311951, 11.641758 , 13.172059 ,\n",
       "        15.890675 , 13.096962 , 14.902825 ],\n",
       "       [ 7.0448046, 15.680967 ,  1.3312143, 11.641773 , 13.172072 ,\n",
       "        15.8907   , 13.096983 , 14.90284  ],\n",
       "       [ 7.0448103, 15.68097  ,  1.3312227, 11.641787 , 13.172077 ,\n",
       "        15.890697 , 13.096987 , 14.902844 ],\n",
       "       [ 7.0448165, 15.6809845,  1.3312349, 11.641789 , 13.172088 ,\n",
       "        15.890718 , 13.097007 , 14.902853 ],\n",
       "       [ 7.04479  , 15.6809435,  1.3311896, 11.641752 , 13.172057 ,\n",
       "        15.890673 , 13.096958 , 14.902819 ],\n",
       "       [ 7.0448127, 15.680977 ,  1.3312287, 11.64179  , 13.172081 ,\n",
       "        15.890707 , 13.096996 , 14.902849 ],\n",
       "       [ 7.04479  , 15.680944 ,  1.3311898, 11.641752 , 13.172055 ,\n",
       "        15.890673 , 13.096958 , 14.902819 ],\n",
       "       [ 7.0448103, 15.680978 ,  1.3312259, 11.641781 , 13.172081 ,\n",
       "        15.890717 , 13.097    , 14.902848 ],\n",
       "       [ 7.044776 , 15.680926 ,  1.3311663, 11.641735 , 13.172041 ,\n",
       "        15.890648 , 13.096932 , 14.9028015]], dtype=float32), label_ids=array([[4., 2., 3., 5., 2., 3., 4., 3.],\n",
       "       [4., 4., 5., 1., 1., 1., 2., 2.],\n",
       "       [4., 3., 5., 1., 2., 2., 4., 1.],\n",
       "       [3., 3., 4., 3., 4., 2., 3., 2.],\n",
       "       [4., 2., 5., 1., 1., 1., 5., 1.],\n",
       "       [5., 4., 5., 3., 3., 1., 5., 1.],\n",
       "       [4., 2., 5., 1., 2., 3., 4., 2.],\n",
       "       [5., 2., 2., 3., 4., 1., 3., 1.],\n",
       "       [4., 3., 5., 2., 2., 2., 5., 2.],\n",
       "       [4., 2., 2., 3., 4., 1., 2., 4.],\n",
       "       [4., 4., 5., 2., 4., 2., 4., 1.],\n",
       "       [5., 4., 5., 3., 3., 1., 3., 1.],\n",
       "       [5., 1., 3., 3., 4., 2., 2., 1.],\n",
       "       [5., 3., 4., 1., 5., 2., 4., 1.],\n",
       "       [5., 3., 4., 3., 4., 3., 3., 1.],\n",
       "       [4., 3., 5., 2., 4., 5., 5., 1.]], dtype=float32), metrics={'test_loss': 104.87387084960938, 'test_mse': 104.8738784790039, 'test_rmse': 10.240794816761241, 'test_mae': 9.324854850769043, 'test_r2': -109.490478515625, 'test_runtime': 31.969, 'test_samples_per_second': 0.5, 'test_steps_per_second': 0.063})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
